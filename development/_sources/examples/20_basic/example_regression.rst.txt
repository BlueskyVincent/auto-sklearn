
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/20_basic/example_regression.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_examples_20_basic_example_regression.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_20_basic_example_regression.py:


==========
Regression
==========

The following example shows how to fit a simple regression model with
*auto-sklearn*.

.. GENERATED FROM PYTHON SOURCE LINES 10-18

.. code-block:: default

    from pprint import pprint

    import sklearn.datasets
    import sklearn.metrics

    import autosklearn.regression
    import matplotlib.pyplot as plt








.. GENERATED FROM PYTHON SOURCE LINES 19-21

Data Loading
============

.. GENERATED FROM PYTHON SOURCE LINES 21-28

.. code-block:: default


    X, y = sklearn.datasets.load_diabetes(return_X_y=True)

    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(
        X, y, random_state=1
    )








.. GENERATED FROM PYTHON SOURCE LINES 29-31

Build and fit a regressor
=========================

.. GENERATED FROM PYTHON SOURCE LINES 31-39

.. code-block:: default


    automl = autosklearn.regression.AutoSklearnRegressor(
        time_left_for_this_task=120,
        per_run_time_limit=30,
        tmp_folder="/tmp/autosklearn_regression_example_tmp",
    )
    automl.fit(X_train, y_train, dataset_name="diabetes")





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/runner/work/auto-sklearn/auto-sklearn/autosklearn/metalearning/metalearning/meta_base.py:76: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
      self.metafeatures = self.metafeatures.append(metafeatures)
    /home/runner/work/auto-sklearn/auto-sklearn/autosklearn/metalearning/metalearning/meta_base.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
      self.algorithm_runs[metric].append(runs)

    AutoSklearnRegressor(per_run_time_limit=30, time_left_for_this_task=120,
                         tmp_folder='/tmp/autosklearn_regression_example_tmp')



.. GENERATED FROM PYTHON SOURCE LINES 40-42

View the models found by auto-sklearn
=====================================

.. GENERATED FROM PYTHON SOURCE LINES 42-45

.. code-block:: default


    print(automl.leaderboard())





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

              rank  ensemble_weight            type      cost  duration
    model_id                                                           
    31           1             0.48  ard_regression  0.428169  0.798670
    25           2             0.26             sgd  0.436679  0.702689
    33           3             0.20   liblinear_svr  0.472547  0.821341
    29           4             0.06  ard_regression  0.493390  0.694937




.. GENERATED FROM PYTHON SOURCE LINES 46-48

Print the final ensemble constructed by auto-sklearn
====================================================

.. GENERATED FROM PYTHON SOURCE LINES 48-51

.. code-block:: default


    pprint(automl.show_models(), indent=4)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    {   25: {   'cost': 0.43667876507897496,
                'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7fc2c54fde20>,
                'ensemble_weight': 0.26,
                'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7fc2c5530220>,
                'model_id': 25,
                'rank': 2,
                'regressor': <autosklearn.pipeline.components.regression.RegressorChoice object at 0x7fc2c55307c0>,
                'sklearn_regressor': SGDRegressor(alpha=0.0006517033225329654, epsilon=0.012150149892783745,
                 eta0=0.016444224834275295, l1_ratio=1.7462342366289323e-09,
                 loss='epsilon_insensitive', max_iter=16, penalty='elasticnet',
                 power_t=0.21521743568582094, random_state=1,
                 tol=0.002431731981071206, warm_start=True)},
        29: {   'cost': 0.49338956176198634,
                'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7fc2c8aa6160>,
                'ensemble_weight': 0.06,
                'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7fc2c599ba60>,
                'model_id': 29,
                'rank': 4,
                'regressor': <autosklearn.pipeline.components.regression.RegressorChoice object at 0x7fc2c599bfa0>,
                'sklearn_regressor': ARDRegression(alpha_1=0.0003658795897322683, alpha_2=8.92755085837738e-05,
                  copy_X=False, lambda_1=2.7018753584355872e-06,
                  lambda_2=1.345477555564763e-07,
                  threshold_lambda=28013.994606205768, tol=0.00033715305179437166)},
        31: {   'cost': 0.428169158594341,
                'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7fc2c59a4c70>,
                'ensemble_weight': 0.48,
                'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7fc2c5952d30>,
                'model_id': 31,
                'rank': 1,
                'regressor': <autosklearn.pipeline.components.regression.RegressorChoice object at 0x7fc2c5952f70>,
                'sklearn_regressor': ARDRegression(alpha_1=0.0008154544266182765, alpha_2=5.59538372768849e-10,
                  copy_X=False, lambda_1=0.0006960494791085091,
                  lambda_2=0.00035440029631338203,
                  threshold_lambda=6133.542143966113, tol=0.004462344005356406)},
        33: {   'cost': 0.4725467145542245,
                'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7fc2c8aafb20>,
                'ensemble_weight': 0.2,
                'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7fc2c55167c0>,
                'model_id': 33,
                'rank': 3,
                'regressor': <autosklearn.pipeline.components.regression.RegressorChoice object at 0x7fc2c304b310>,
                'sklearn_regressor': LinearSVR(C=71.4085586379967, dual=False, epsilon=0.03951022702573597,
              loss='squared_epsilon_insensitive', random_state=1,
              tol=0.006317097934562396)}}




.. GENERATED FROM PYTHON SOURCE LINES 52-58

Get the Score of the final ensemble
===================================
After training the estimator, we can now quantify the goodness of fit. One possibility for
is the `R2 score <https://scikit-learn.org/stable/modules/model_evaluation.html#r2-score>`_.
The values range between -inf and 1 with 1 being the best possible value. A dummy estimator
predicting the data mean has an R2 score of 0.

.. GENERATED FROM PYTHON SOURCE LINES 58-64

.. code-block:: default


    train_predictions = automl.predict(X_train)
    print("Train R2 score:", sklearn.metrics.r2_score(y_train, train_predictions))
    test_predictions = automl.predict(X_test)
    print("Test R2 score:", sklearn.metrics.r2_score(y_test, test_predictions))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Train R2 score: 0.5922043282790412
    Test R2 score: 0.4073119977311549




.. GENERATED FROM PYTHON SOURCE LINES 65-72

Plot the predictions
====================
Furthermore, we can now visually inspect the predictions. We plot the true value against the
predictions and show results on train and test data. Points on the diagonal depict perfect
predictions. Points below the diagonal were overestimated by the model (predicted value is higher
than the true value), points above the diagonal were underestimated (predicted value is lower than
the true value).

.. GENERATED FROM PYTHON SOURCE LINES 72-83

.. code-block:: default


    plt.scatter(train_predictions, y_train, label="Train samples", c="#d95f02")
    plt.scatter(test_predictions, y_test, label="Test samples", c="#7570b3")
    plt.xlabel("Predicted value")
    plt.ylabel("True value")
    plt.legend()
    plt.plot([30, 400], [30, 400], c="k", zorder=0)
    plt.xlim([30, 400])
    plt.ylim([30, 400])
    plt.tight_layout()
    plt.show()



.. image-sg:: /examples/20_basic/images/sphx_glr_example_regression_001.png
   :alt: example regression
   :srcset: /examples/20_basic/images/sphx_glr_example_regression_001.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 2 minutes  1.397 seconds)


.. _sphx_glr_download_examples_20_basic_example_regression.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: images/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/automl/auto-sklearn/master?urlpath=lab/tree/notebooks/examples/20_basic/example_regression.ipynb
      :alt: Launch binder
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: example_regression.py <example_regression.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: example_regression.ipynb <example_regression.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
